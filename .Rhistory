}
## GET TRAINING DATA
## variable train_data
directory<- "/Users/winstonsaunders/Documents/pdxkagglegroupproductclassproject/"
file_name<- "train.csv"
train_data<-read.csv(paste0(directory,file_name))
## ensure proper read of data
cat("the dimensions of loaded train_data are: ",dim(train_data)[1], " rows X ", dim(train_data)[2], "columns","\n")
sample_data<-TRUE
set.seed(8675309)
if (sample_data == TRUE){
sample_rows <- sample(1:nrow(train_data), size=RF_sample*nrow(train_data))
## create two data sets
td<-train_data[sample_rows,]
train_data2<-train_data[-sample_rows,]
## create a third, smaller sample for intermediate evaluation
sample_rows2<- sample(1:nrow(train_data2), size=GBM_sample*nrow(train_data2))
## create two data sets, preserving teh name of the first
train_data2<-train_data2[sample_rows2,]
eval_data<-train_data2[-sample_rows2,]
## reassign train data
train_data<-td
}
cat("the dimensions of RF train_data are: ",dim(train_data)[1], " rows X ", dim(train_data)[2], "columns","\n")
cat("the dimensions of GBM train_data2 are: ",dim(train_data2)[1], " rows X ", dim(train_data2)[2], "columns","\n")
cat("the dimensions of eval_data are: ",dim(eval_data)[1], " rows X ", dim(eval_data)[2], "columns","\n")
## RESERVE DATA
train_data_full<-train_data
train_data2_full<-train_data2
eval_data_full<-eval_data
train_data<-group_234(train_data)
train_data2<-group_234(train_data2)
eval_data<-group_234(eval_data)
td<-train_data
## Random forest Model
set.seed(8765309)
start_time <- proc.time()
cat("computing RF \n")
categorization_model <- randomForest(group~.-id-target, data=td, importance=TRUE, ntree=P_ntree, nodesize=P_nodesize)
finish_time<-proc.time()
elapsed_time<-finish_time-start_time
cat("time ", elapsed_time, " seconds \n")
predict_categorization_input<-eval_data
categorization_predict<-predict(categorization_model, newdata=predict_categorization_input, type="prob")
categorization_predict<-as.data.frame(categorization_predict)
categorization_predict<- as.factor(colnames(categorization_predict)[max.col(categorization_predict)])
print(table(categorization_predict, eval_data$group))
check<-table(categorization_predict==eval_data$group)
accuracy<-1-check[1]/(check[1]+check[2])
cat("accuracy of rf is ", round(100*accuracy,2), "%","\n")
td<-train_data
## split data into groups
td_gr1<-td[td$group=="group_1", ]
td_gr234<-td[td$group=="group_234", ]
td_gr234<-droplevels(td_gr234)
## get rid of group designator
td_gr234$group<-NULL
ggplot(td_gr234, aes(y=feat_67, x = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_67, x = feat_68, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_67, x = feat_68, color = target))+geom_point()
ggplot(td_gr234, aes(y=feat_66, x = feat_68, color = target))+geom_point()
ggplot(td_gr234, aes(y=feat_92, x = feat_79, color = target))+geom_point()
ggplot(td_gr234, aes(y=feat_92, x = feat_76, color = target))+geom_point()
ggplot(td_gr234, aes(y=feat_89, x = feat_77, color = target))+geom_point()
ggplot(td_gr234, aes(y=feat_89, x = feat_77, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_90, x = feat_92, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_1, x = feat_2, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_3, x = feat_4, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_5, x = feat_6, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_7, x = feat_8, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_9, x = feat_10, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_11, x = feat_12, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_13, x = feat_14, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_14, x = feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_17, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_17, x = feat_18, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_19, x = feat_20, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_21, x = feat_22, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_23, x = feat_24, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_23, x = feat_89, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_23, x = feat_24, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_25, x = feat_26, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_27, x = feat_28, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_29, x = feat_30, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_31, x = feat_32, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_32, x = feat_32, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_32, x = feat_10, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_15, x = feat_15*feat_16, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_32, x = feat_33, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_32, x = feat_33*feat_32, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_34, x = feat_33*feat_32, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=feat_34*feat_35, x = feat_33*feat_32, color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_34*feat_35), x = sqrt(feat_33*feat_32), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_1*feat_2), x = sqrt(feat_3*feat_4), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_4*feat_5), x = sqrt(feat_3*feat_4), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_4*feat_5), x = sqrt(feat_6*feat_7), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_4*feat_5), x = sqrt(feat_6*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_7), x = sqrt(feat_6*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_7), x = sqrt(feat_5*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_6), x = sqrt(feat_5*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_7*feat_7), x = sqrt(feat_5*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_7), x = sqrt(feat_5*feat_5), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_7), x = sqrt(feat_5*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_5*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_6), x = sqrt(feat_5*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_5*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_6*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_7*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_8*feat_9), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_6*feat_8), x = sqrt(feat_8*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_11*feat_8), x = sqrt(feat_8*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_11*feat_10), x = sqrt(feat_8*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_11*feat_10), x = sqrt(feat_12*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_12*feat_10), x = sqrt(feat_12*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_13*feat_10), x = sqrt(feat_12*feat_10), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_13*feat_12), x = sqrt(feat_12*feat_10), color = target))+geom_jitter()
td_gr234$group<-NULL
## explore data correlations
ggplot(td_gr234, aes(y=sqrt(feat_13*feat_12), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_14*feat_13), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_14*feat_15), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_16*feat_15), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_16*feat_17), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_18*feat_17), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_19*feat_18), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_19*feat_20), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_19*feat_21), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_18*feat_21), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_20*feat_21), x = sqrt(feat_12*feat_11), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_20*feat_21), x = sqrt(feat_21*feat_22), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_20*feat_21), x = sqrt(feat_22*feat_23), color = target))+geom_jitter()
ggplot(td_gr234, aes(y=sqrt(feat_23*feat_24), x = sqrt(feat_22*feat_23), color = target))+geom_jitter()
version()
?version
R.version()
R.Version()
R.version.string
R.version.string
install.packages(c("class", "devtools", "foreign", "MASS", "nlme", "nnet", "raster", "rgl", "RMySQL", "sp", "spatial"))
p <- p + scale_color_manual(values = c("red", "green", "light green", "dark green", "green", "blue", "blue"))
rainbowcolors(3)
rainbow(5)
library(ggplot2)
?scale_color_manual
?rpart
library(rpart)
?rpart
prp(treefit, uniform=TRUE, main="Classification Tree for Crashes",type=2, extra=2, faclen=0)
prp(treefit, uniform=TRUE, main="Classification Tree for Crashes",type=3, extra=2, faclen=0)
aa<-matrix(1:6, nrow=2)
aa
b<-c("TRUE", "TRUE", "FALSE")
d<-c("TRUE", "FALSE", "TRUE")
table(b,d)
str(table(b,d))
?matrix
library(caret)
lvs <- c("normal", "abnormal")
truth <- factor(rep(lvs, times = c(86, 258)),
levels = rev(lvs))
str(truth)
length(truth)
truth
pred <- factor(
c(
rep(lvs, times = c(54, 32)),
rep(lvs, times = c(27, 231))),
levels = rev(lvs))
xtab <- table(pred, truth)
confusionMatrix(xtab)
confusionMatrix(pred, truth)
confusionMatrix(xtab, prevalence = 0.25)
confusionMatrix(xtab)
confusionMatrix(pred, truth)
confusionMatrix(xtab, prevalence = 0.25)
confusionMatrix(xtab, prevalence = 0.5)
confusionMatrix(iris$Species, sample(iris$Species))
library(ggmap)
lat_x<-c(44.423313,44.424651,44.425309,44.422249,44.423021,44.430295,44.429037,44.429494,44.436968,44.433081,44.430264,44.423979)
lon_x<-x(-121.802764,-121.824192,-121.842798, -121.856786,-121.878365, -121.882923,-121.902021,-121.923218,-121.940328,-121.957209,-121.976371,-121.994433)
lat_x<-c(44.423313,44.424651,44.425309,44.422249,44.423021,44.430295,44.429037,44.429494,44.436968,44.433081,44.430264,44.423979)
lon_x<-c(-121.802764,-121.824192,-121.842798, -121.856786,-121.878365, -121.882923,-121.902021,-121.923218,-121.940328,-121.957209,-121.976371,-121.994433)
santiam_loc<-c(lat=44.42225, lon=-121.8567)
santiam_map<-get_map(location=santiam_loc, source="osm", color="bw", zoom=10)
santiam_loc<-c(lon=-121.8567,lat=44.42225)
santiam_map<-get_map(location=santiam_loc, source="osm", color="bw", zoom=10)
ggmap(santiam_map)
santiam_map<-get_map(location=santiam_loc, source="osm", zoom=12)
ggmap(santiam_map)
santiam_rect<-c(-122.3,44.50,-121.5,44.35)
santiam_map<-get_map(location=santiam_rec, source="osm")
santiam_map<-get_map(location=santiam_rect, source="osm")
ggmap(santiam_map)
santiam_rect<-c(-122.3,44.50,-121.5,44.35)
santiam_loc<-c(lon=-121.8967,lat=44.42225)
santiam_map<-get_map(location=santiam_loc, source="osm", zoom=12)
ggmap(santiam_map)
santiam_map<-get_map(location=santiam_loc, source="google", maptype="satellite", zoom=12)
ggmap(santiam_map)
santiam_map<-get_map(location=santiam_loc, source="google", maptype="terrain", zoom=12)
ggmap(santiam_map)
mile_marks<-as.data.frame(cbind("lon"=lon_x, "lat"=lat_x))
mile_marks
santiam_map<-santiam_map + geom_point(aes(x=lon, y = lat, size=5), data=mile_marks, color="darkred")
santiam_map<-get_map(location=santiam_loc, source="google", maptype="terrain", zoom=12)
ggmap(santiam_map)+ geom_point(aes(x=lon, y = lat, size=5), data=mile_marks, color="darkred")
santiam_map<-get_map(location=santiam_loc, source="google", maptype="terrain", zoom=11)
ggmap(santiam_map)+ geom_point(aes(x=lon, y = lat, size=5), data=mile_marks, color="darkred")
x<-sample(1:10, 30)
?sample.int
x<-sample.int(1:10, 15)
x<-sample.int(1:10, 15, replace=TRUE)
x
x<-sample(1:10, 15, replace=TRUE)
x
table(X)
table(x)
x<-sample(1:10, 200, replace=TRUE)
xt<-table(x)
xt
as.data.frame(xt)
install.packages(c("adabag", "caret", "coda", "DescTools", "DiagrammeR", "doMC", "doParallel", "doSNOW", "fields", "foreach", "iterators", "ks", "lme4", "raster", "rgl", "RMySQL", "RUnit", "snowfall", "sp", "spatstat", "testthat", "treemap", "V8"))
hwy_df<-read.csv(paste0(file_name, ".csv"))
##make the date column a date
library(bitops)
library(RCurl)
##This program assumes you have already run the TwitterReader.R to download a feed timeline.
##It reads the data from teh twitter API and stores it in the form of a .csv
## Get the relevant tweet data
if (getwd()=="/Users/winstonsaunders/Documents") {setwd("TripcheckR")}
if (getwd()!="/Users/winstonsaunders/Documents/TripcheckR") {setwd("/Users/winstonsaunders/Documents/TripcheckR")}
file_name <- "TripCheckUS20B_Sep15"
hwy_df<-read.csv(paste0(file_name, ".csv"))
hwy_df$created<-as.character(hwy_df$created)
hwy_df$text<-as.character(hwy_df$text)
##make the date column a date
hwy_df$date<-as.Date(hwy_df$created)
## create pacific time column
hwy_df$PDT<-as.POSIXct(hwy_df$created, tz="UTC")
## convert to Pacific time
attributes(hwy_df$PDT)$tzone<-"US/Pacific"
##make an "hour" column (for time of day)
library(lubridate)
t.lub <- ymd_hms(hwy_df$PDT)
hwy_df$hour <- hour(t.lub) + minute(t.lub)/60
## make a seconds column
hwy_df$chronsecs<-as.numeric(as.POSIXlt(hwy_df$PDT))
## create "dayperiod"
hwy_df$dayperiod<-NA
hwy_df$dayperiod[hwy_df$hour>=3 & hwy_df$hour<9]<-"morning"
hwy_df$dayperiod[hwy_df$hour>=9 & hwy_df$hour<15]<-"midday"
hwy_df$dayperiod[hwy_df$hour>=15 & hwy_df$hour<21]<-"evening"
hwy_df$dayperiod[hwy_df$hour>=19]<-"night"
hwy_df$dayperiod[hwy_df$hour<3]<-"night"
## make a factor
hwy_df$dayperiod<-as.factor(hwy_df$dayperiod)
#head(hwy_df)
### capture start and edn times of period
tEnd <- as.Date(hwy_df$created)[length(hwy_df$created)]
tStart <- as.Date(hwy_df$created[1])
```
trip_incident_filter <- function(data_df, incident = "crash"){
hwy_inc <-data_df[grep(tolower(incident), tolower(data_df$text)),]
return(hwy_inc)
library(xtable)
temptable<-xtable(hwy_df[1:8,c(1,2,4,5,7)])
print(temptable, type="html", size="small")
hwy_crash<-trip_incident_filter(hwy_df, "crash")
trip_incident_filter <- function(data_df, incident = "crash"){
##FUNCTION filtering text of tweets for incidents
##accepts data frame requiring:
## text field to search
## returns:
## fitered data with added column called hourdelta (in hours)
##filter incidencts
hwy_inc <-data_df[grep(tolower(incident), tolower(data_df$text)),]
return(hwy_inc)
}
inc_dedupe <- function(hwy_inc){
## reduce duplicates
## add column hourdelta to df
## uses chronsecs
## reverse oder
hwy_inc <- hwy_inc[rev(rownames(hwy_inc)),]
## compute time difference between entries
hwy_inc$hourdelta<-c((3*3600+1),diff(hwy_inc$chronsecs, lag=1))/3600
hwy_inc<-hwy_inc[hwy_inc$hourdelta>3, ]
hwy_inc <- hwy_inc[rev(rownames(hwy_inc)),]
return(hwy_inc)
}
##Filter
hwy_crash<-trip_incident_filter(hwy_df, "crash")
hwy_snow<-trip_incident_filter(hwy_df, "snow")
hwy_crash_santiam<-trip_incident_filter(hwy_crash, "santiam")
hwy_crash_santiam<-inc_dedupe(hwy_crash_santiam)
bb<-hwy_crash_santiam
hwy_crash_santiam<-bb
trip_incident_filter <- function(data_df, incident = "crash"){
##FUNCTION filtering text of tweets for incidents
##accepts data frame requiring:
## text field to search
## returns:
## fitered data with added column called hourdelta (in hours)
##filter incidencts
hwy_inc <-data_df[grep(tolower(incident), tolower(data_df$text)),]
return(hwy_inc)
}
inc_dedupe <- function(hwy_inc){
## reduce duplicates
## add column hourdelta to df
## uses chronsecs
## reverse oder
hwy_inc <- hwy_inc[rev(rownames(hwy_inc)),]
## compute time difference between entries
hwy_inc$hourdelta<-c((3*3600+1),diff(hwy_inc$chronsecs, lag=1))/3600
hwy_inc<-hwy_inc[hwy_inc$hourdelta>3, ]
hwy_inc <- hwy_inc[rev(rownames(hwy_inc)),]
return(hwy_inc)
}
##Filter
hwy_crash<-trip_incident_filter(hwy_df, "crash")
hwy_snow<-trip_incident_filter(hwy_df, "snow")
head(hwy_snow)
hwy_crash_santiam<-trip_incident_filter(hwy_crash, "santiam")
hwy_crash_santiam<-inc_dedupe(hwy_crash_santiam)
bb<-hwy_crash_santiam
hwy_crash_santiam<-bb
## define time units
hour.pos <- seq(0, 12, 12/(12*60))[1:720]
min.pos <-seq(0,12, 12/60)[1:60]
all.hours <- rep(hour.pos, 2)
## DEFINE PLOT THEME
## colors
bach_brown<-"#6A534B"
bach_darkblue<-"#354B60"
bach_lightblue<-"#696468"
bach_darkdarkblue<-"#1E2F37"
bach_skyblue<-"#375C91"
santiam_theme <- function() {
theme(
plot.background = element_rect(fill = 'grey76', colour = 'grey76'),
panel.background = element_rect(fill = "grey76"),
panel.background = element_rect(fill = "grey70"),
axis.text = element_text(colour = bach_darkdarkblue, family = "Arial", size = 10),
plot.title = element_text(colour = bach_darkdarkblue, face = "bold", size = 18, vjust = 1, family = "Arial"),
axis.title = element_text(colour = "black", face = "bold", size = 14, family = "Arial"),
panel.grid.major.x = element_line(colour = bach_lightblue),
panel.grid.minor.x = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank(),
strip.text = element_text(family = "Impact", colour = "white"),
strip.background = element_rect(fill = bach_darkblue),
axis.ticks = element_line(colour = bach_darkblue),
legend.position="none"
)
}
santiam_theme2 <- function() {
theme(
plot.background = element_rect(fill = 'white', colour = 'white'),
panel.background = element_rect(fill = "grey76"),
legend.background = element_rect(fill="gray70"),
axis.text = element_text(colour = bach_darkdarkblue, family = "Arial", size = 10),
plot.title = element_text(colour = bach_darkdarkblue, face = "bold", size = 18, vjust = 1, family = "Arial"),
axis.title = element_text(colour = "black", face = "bold", size = 14, family = "Arial"),
#panel.grid.major.x = element_line(colour = bach_lightblue),
#panel.grid.minor.x = element_blank(),
#panel.grid.major.y = element_blank(),
#panel.grid.minor.y = element_blank(),
strip.text = element_text(family = "Impact", colour = "white"),
strip.background = element_rect(fill = bach_darkblue),
axis.ticks = element_line(colour = bach_darkblue)
)
}
hwy_crash_santiam<-trip_incident_filter(hwy_crash, "santiam")
library(timeDate)
snow_days<-hwy_snow$date
head(snow_days)
length(snow_days)
snow_x<-unique(snow_days)
length(snow_x)
snow_days<-unique(snow_days)
hwy_df<-read.csv(paste0(file_name, ".csv"))
##make the date column a date
hwy_df$created<-as.Date(hwy_df$created)
##Define Search Patterns
location <- "Santiam Pass Summit"
##Get tweets with S1
hwy_df <-hwy_df[grep(location, hwy_df$text),]
incident <- "crash"
## get tweets with S2
hwy_df <-hwy_df[grep(incident, hwy_df$text),]
##dedup the data
hwy_df<-hwy_df[!duplicated(hwy_df$created),]
##analyze the data
## get some details on the crash from the text string
##Find "Mi" maker and then extract miles number
midist<-lapply(hwy_df$text, function(x) {y<- regexpr("Mi", x)
if (y >4) substring(x,y-3,y-1)
else "NA"})
# if (y != FALSE) substring(x, y-3, y-1)})
distance<-as.numeric(midist)
direction<-lapply(hwy_df$text, function(x) {y<- regexpr("Mi", x)
if (y >4) substring(x,y+2,y+3)
else "NA"})
hwy_df$text<-substring(hwy_df$text,7,12)
direction<-as.character(direction)
##bind new columns to data frame
plotdata<-cbind(hwy_df, distance, direction )
print(head(plotdata))
##reduce dimensions
plotdata<-plotdata[,c(6,18,19)]
head(plotdata)
install.packages("pROC")
library(pROC)
data(aSAH)
# Build a ROC object and compute the AUC
roc(aSAH$outcome, aSAH$s100b)
roc(outcome ~ s100b, aSAH)
roc(outcome ~ s100b, aSAH, smooth=TRUE, plot=TRUE)
roc(test_df$crash~ acc_pred, test_df, smooth=TRUE, plot=TRUE)
library(randomForest)
## get rid of holiday classifier
Analysis_df_t<- subset(Analysis_df, select = -holiday )
set.seed(8675309)
sample_subset<-sample(1:nrow(Analysis_df), 0.6*nrow(Analysis_df))
train_df <- Analysis_df[sample_subset,]
test_df <- Analysis_df[-sample_subset,]
rF_fit<-randomForest(crash~snow+weekday, train_df, method="class", importance=TRUE)
acc_pred<-predict(rF_fit, test_df[,-test_df$crash])
tStart <- hwy_df$date[1]
tEnd <- hwy_df$date[nrow(hwy_df)]
##Start with dates
Tvect<-tStart:tEnd
date<-as.Date(Tvect, "1970-01-01")
Analysis_df<-as.data.frame(date)
#head(Analysis_df)
Analysis_df$crash <- (Analysis_df$date %in% hwy_crash_santiam$date)
Analysis_df$snow <- (Analysis_df$date %in% hwy_snow$date)
## copute confusion matrix
confusion_table<-table(Analysis_df$crash, Analysis_df$snow)
##make factors in natural language
#Analysis_df$snow[Analysis_df$snow==TRUE]<-"snow"
#Analysis_df$snow [Analysis_df$snow ==FALSE]<-"none"
Analysis_df$snow <-as.character(Analysis_df$snow )
Analysis_df$snow <- as.factor(Analysis_df$snow )
#     Analysis_df$dayperiod <- rep("none", nrow(Analysis_df))
#
#     ## add day period
#     Analysis_df$midday<-(Analysis_df$date %in% hwy_crash_santiam$date[hwy_crash_santiam$dayperiod=="midday"])
#
#     Analysis_df$dayperiod[Analysis_df$midday==TRUE]<- "midday"
#
#     Analysis_df$evening<-(Analysis_df$date %in% hwy_crash_santiam$date[hwy_crash_santiam$dayperiod=="evening"])
#
#     Analysis_df$dayperiod[Analysis_df$evening=="evening"]<- "evening"
#
#     Analysis_df$night<-(Analysis_df$date %in% hwy_crash_santiam$date[hwy_crash_santiam$dayperiod=="night"])
#
#     Analysis_df$dayperiod[Analysis_df$night==TRUE]<- "night"
#
#     Analysis_df$morning<-(Analysis_df$date %in% hwy_crash_santiam$date[hwy_crash_santiam$dayperiod=="morning"])
#
#     Analysis_df$dayperiod[Analysis_df$morning==TRUE]<- "morning"
#
#     drops=c("midday", "morning", "night", "evening")
#
#     Analysis_df<-Analysis_df[,!(names(Analysis_df)%in%drops)]
Analysis_df$weekday <- weekdays(as.Date(Analysis_df$date, "1970-01-01"))
##Holidays
library(timeDate)
holidays_list = holidayNYSE(2005:2015)
holidays_df<-as.Date(holidays_list)
Analysis_df$holiday <-  (Analysis_df$date %in% holidays_df)
#Analysis_df$holiday[Analysis_df$holiday==TRUE]<-"holiday"
#Analysis_df$holiday[Analysis_df$holiday==FALSE]<-"nonholiday"
Analysis_df$holiday <- as.factor(Analysis_df$holiday)
## assign label
#Analysis_df$holiday[Analysis_df$holiday == TRUE] <- "holiday"
#Analysis_df$holiday[Analysis_df$holiday == FALSE] <- "nonholiday"
#Analysis_df$holiday<-as.factor(Analysis_df$holiday)
## Add weekend
Analysis_df$weekend <- Analysis_df$weekday == "Sunday" | Analysis_df$weekday == "Saturday"
## Long Weekend
Analysis_df$longweekend<-rep(FALSE, nrow(Analysis_df))
for (i in 3:(length(Analysis_df$date-3))) {
## Mondays
if (Analysis_df[i, "weekday"] == "Monday" & Analysis_df[i,"holiday"] == TRUE){
Analysis_df[i, "longweekend"] <- TRUE
Analysis_df[i+1, "longweekend"] <- TRUE
Analysis_df[i+2, "longweekend"] <- TRUE
}
## Fridays
if (Analysis_df[i, "weekday"] == "Friday" & Analysis_df[i, "holiday"] == TRUE){
Analysis_df[i, "longweekend"] <- TRUE
Analysis_df[i-1, "longweekend"] <- TRUE
Analysis_df[i-2, "longweekend"] <- TRUE
}
## Thursdays
if (Analysis_df[i, "weekday"] == "Thursday" & Analysis_df[i, "holiday"] == TRUE){
Analysis_df[i, "longweekend"] <- TRUE
Analysis_df[i-1, "longweekend"] <- TRUE
Analysis_df[i-2, "longweekend"] <- TRUE
Analysis_df[i-2, "longweekend"] <- TRUE
}
}
Analysis_df$weekday<-as.factor(Analysis_df$weekday)
Analysis_df$longweekend<-as.factor(Analysis_df$longweekend)
head(Analysis_df)
